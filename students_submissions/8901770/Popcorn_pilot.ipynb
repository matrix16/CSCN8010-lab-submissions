{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSCN8010 - Fall 2023 - Foundations of Machine Learning Frameworks Assignment 2 - Final Project\n",
    "#### Project Name : Popcorn Pilot\n",
    " - Authors\n",
    " - Sam Hussain Hajanajumudeen(8901770)\n",
    " - Rohit Khadka (8899399)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Clear Problem Statement (Objective, Motivation, Method):</b>\n",
    "\n",
    "Objective: The project, named \"Popcorn Pilot,\" aims to develop a movie recommendation system. Given a movie name as input, the system will suggest other movies based on various factors such as genre, story, and plot.\n",
    "\n",
    "Motivation: The motivation behind this project is to enhance the movie-watching experience by providing personalized recommendations, making it easier for users to discover films that align with their preferences.\n",
    "\n",
    "Method: The recommendation system will be built using machine learning techniques. The model will be trained on a dataset containing information about movies from IMDB, considering features like genre, story details, and plot summaries.\n",
    "\n",
    "<b>2. Interesting Choice of Problem</b>\n",
    "\n",
    "The problem of movie recommendation is interesting as it involves applying machine learning to provide personalized suggestions, making it engaging for users.\n",
    "\n",
    "<b>3. Reasonable (Doable) Choice of Problem</b>\n",
    "\n",
    "The choice of building a movie recommendation system based on IMDB data is reasonable and feasible, considering the availability of a rich dataset and established methods for building such systems.\n",
    "\n",
    "<b>4. Review of the Data Source</b>\n",
    "\n",
    "The dataset for this project will be sourced from IMDB, a reputable and comprehensive database of movies. It's crucial to highlight the characteristics and size of the dataset, ensuring it contains the necessary information for effective model training.\n",
    "\n",
    "<b>5. Indication of Reference Code</b>\n",
    "\n",
    "I mention that it is to refer to relevant machine learning and recommendation system code examples, libraries, or frameworks. This could include using Python with libraries like scikit-learn\n",
    "\n",
    "<b>Proposal :</b>\n",
    "\n",
    "I am proposing a project titled \"Popcorn Pilot\" which involves the development of a movie recommendation system. The objective is to provide users with personalized movie suggestions based on genre, story, and plot details. The motivation behind this project is to enhance the overall movie-watching experience by offering tailored recommendations.\n",
    "\n",
    "The chosen method for building the recommendation system involves utilizing machine learning techniques. The model will be trained on a dataset sourced from IMDB, a renowned database of movies. This dataset will contain crucial information such as genre, story details, and plot summaries.\n",
    "\n",
    "The problem of movie recommendation is interesting, as it not only involves applying machine learning concepts but also contributes to user satisfaction by simplifying the process of discovering movies aligned with their preferences. The choice of using IMDB data is reasonable and feasible, considering the availability of a comprehensive dataset and established methods for building recommendation systems. \n",
    "\n",
    "To ensure the successful implementation of the project, I plan to review relevant machine learning and recommendation system code examples, leveraging Python and possibly libraries like scikit-learn or TensorFlow.\n",
    "\n",
    "This project holds the potential to provide a valuable and enjoyable service to movie enthusiasts, simplifying their movie selection process and introducing them to films they might have otherwise missed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Downloading the Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the-movies-dataset.zip to d:\\Fall_2023\\course\\AI_ML_8010\\Final Project\\project\\popcorn-pilot\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/228M [00:00<?, ?B/s]\n",
      "  0%|          | 1.00M/228M [00:00<00:32, 7.36MB/s]\n",
      "  2%|▏         | 4.00M/228M [00:00<00:12, 19.1MB/s]\n",
      "  4%|▎         | 8.00M/228M [00:00<00:09, 25.1MB/s]\n",
      "  5%|▌         | 12.0M/228M [00:00<00:08, 27.9MB/s]\n",
      "  7%|▋         | 16.0M/228M [00:00<00:07, 29.3MB/s]\n",
      "  9%|▉         | 20.0M/228M [00:00<00:07, 30.4MB/s]\n",
      " 11%|█         | 24.0M/228M [00:00<00:06, 30.8MB/s]\n",
      " 12%|█▏        | 28.0M/228M [00:01<00:06, 31.3MB/s]\n",
      " 14%|█▍        | 32.0M/228M [00:01<00:06, 31.5MB/s]\n",
      " 16%|█▌        | 36.0M/228M [00:01<00:06, 31.8MB/s]\n",
      " 18%|█▊        | 40.0M/228M [00:01<00:06, 31.9MB/s]\n",
      " 19%|█▉        | 44.0M/228M [00:01<00:06, 31.9MB/s]\n",
      " 21%|██        | 48.0M/228M [00:01<00:05, 32.0MB/s]\n",
      " 23%|██▎       | 52.0M/228M [00:01<00:05, 32.0MB/s]\n",
      " 25%|██▍       | 56.0M/228M [00:01<00:05, 32.0MB/s]\n",
      " 26%|██▋       | 60.0M/228M [00:02<00:05, 32.0MB/s]\n",
      " 28%|██▊       | 64.0M/228M [00:02<00:05, 32.1MB/s]\n",
      " 30%|██▉       | 68.0M/228M [00:02<00:05, 32.1MB/s]\n",
      " 32%|███▏      | 72.0M/228M [00:02<00:05, 32.0MB/s]\n",
      " 33%|███▎      | 76.0M/228M [00:02<00:04, 32.1MB/s]\n",
      " 35%|███▌      | 80.0M/228M [00:02<00:04, 32.1MB/s]\n",
      " 37%|███▋      | 84.0M/228M [00:02<00:04, 32.2MB/s]\n",
      " 39%|███▊      | 88.0M/228M [00:02<00:04, 32.1MB/s]\n",
      " 40%|████      | 92.0M/228M [00:03<00:04, 32.0MB/s]\n",
      " 42%|████▏     | 96.0M/228M [00:03<00:04, 32.1MB/s]\n",
      " 44%|████▍     | 100M/228M [00:03<00:04, 32.1MB/s] \n",
      " 46%|████▌     | 104M/228M [00:03<00:04, 32.0MB/s]\n",
      " 47%|████▋     | 108M/228M [00:03<00:03, 32.3MB/s]\n",
      " 49%|████▉     | 112M/228M [00:03<00:03, 32.1MB/s]\n",
      " 51%|█████     | 116M/228M [00:03<00:03, 32.0MB/s]\n",
      " 53%|█████▎    | 120M/228M [00:04<00:03, 32.1MB/s]\n",
      " 54%|█████▍    | 124M/228M [00:04<00:03, 32.2MB/s]\n",
      " 56%|█████▌    | 128M/228M [00:04<00:03, 32.1MB/s]\n",
      " 58%|█████▊    | 132M/228M [00:04<00:03, 32.1MB/s]\n",
      " 60%|█████▉    | 136M/228M [00:04<00:02, 32.1MB/s]\n",
      " 61%|██████▏   | 140M/228M [00:04<00:02, 32.1MB/s]\n",
      " 63%|██████▎   | 144M/228M [00:04<00:02, 31.9MB/s]\n",
      " 65%|██████▍   | 148M/228M [00:04<00:02, 32.2MB/s]\n",
      " 67%|██████▋   | 152M/228M [00:05<00:02, 31.2MB/s]\n",
      " 68%|██████▊   | 155M/228M [00:05<00:03, 23.6MB/s]\n",
      " 70%|██████▉   | 159M/228M [00:05<00:02, 25.9MB/s]\n",
      " 72%|███████▏  | 163M/228M [00:05<00:02, 27.3MB/s]\n",
      " 73%|███████▎  | 167M/228M [00:05<00:02, 28.9MB/s]\n",
      " 75%|███████▌  | 171M/228M [00:05<00:01, 29.9MB/s]\n",
      " 76%|███████▋  | 174M/228M [00:05<00:01, 29.9MB/s]\n",
      " 78%|███████▊  | 178M/228M [00:06<00:01, 31.1MB/s]\n",
      " 80%|███████▉  | 182M/228M [00:06<00:01, 31.4MB/s]\n",
      " 82%|████████▏ | 186M/228M [00:06<00:01, 31.6MB/s]\n",
      " 83%|████████▎ | 190M/228M [00:06<00:01, 31.7MB/s]\n",
      " 85%|████████▌ | 194M/228M [00:06<00:01, 31.8MB/s]\n",
      " 87%|████████▋ | 198M/228M [00:06<00:00, 31.6MB/s]\n",
      " 89%|████████▊ | 202M/228M [00:06<00:00, 31.8MB/s]\n",
      " 90%|█████████ | 206M/228M [00:06<00:00, 31.9MB/s]\n",
      " 92%|█████████▏| 210M/228M [00:07<00:00, 32.0MB/s]\n",
      " 94%|█████████▍| 214M/228M [00:07<00:00, 32.0MB/s]\n",
      " 96%|█████████▌| 218M/228M [00:07<00:00, 32.0MB/s]\n",
      " 97%|█████████▋| 222M/228M [00:07<00:00, 32.0MB/s]\n",
      " 99%|█████████▉| 226M/228M [00:07<00:00, 32.1MB/s]\n",
      "100%|██████████| 228M/228M [00:07<00:00, 31.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d rounakbanik/the-movies-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extacting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!powershell Expand-Archive -Path 'the-movies-dataset.zip' -DestinationPath './content/data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet fastparquet\n",
    "!pip install --quiet pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Rerquired Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Data Cleaning & Engineering\n",
    "\n",
    ">     Information on preparing data for trainable features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions For Data Cleaning & Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_director(x):\n",
    "    \"\"\"\n",
    "    Extract the Name of the Director for a movie if it is present inside the job\n",
    "    \"\"\"\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading dataset and merging them to form master dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset = pd.read_csv('./content/data/movies_metadata.csv')\n",
    "credits = pd.read_csv('./content/data/credits.csv')\n",
    "keywords = pd.read_csv('./content/data/keywords.csv')\n",
    "links = pd.read_csv('./content/data/links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping these 3 rows because Date Column value for them is string date instead of Int with ID.\n",
    "movies_dataset = movies_dataset.drop([19730, 29503, 35587])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Genres of movies from the genres dictionary. If not present, append empty list\n",
    "movies_dataset['genres'] = movies_dataset['genres'].fillna('[]').apply(\n",
    "    literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to common data type for primary key in our dataset\n",
    "keywords['id'] = keywords['id'].astype('int')\n",
    "credits['id'] = credits['id'].astype('int')\n",
    "movies_dataset['id'] = movies_dataset['id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging movies dataset with credits & keywords to form master dataset\n",
    "movies_dataset = movies_dataset.merge(credits, on='id')\n",
    "master_dataset = movies_dataset.merge(keywords, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
       "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
       "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[Adventure, Fantasy, Family]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
       "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
       "      <td>[{'id': 10090, 'name': 'board game'}, {'id': 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "\n",
       "                         genres                              homepage    id  \\\n",
       "0   [Animation, Comedy, Family]  http://toystory.disney.com/toy-story   862   \n",
       "1  [Adventure, Fantasy, Family]                                   NaN  8844   \n",
       "\n",
       "     imdb_id original_language original_title  \\\n",
       "0  tt0114709                en      Toy Story   \n",
       "1  tt0113497                en        Jumanji   \n",
       "\n",
       "                                            overview  ...  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...   \n",
       "1  When siblings Judy and Peter discover an encha...  ...   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "\n",
       "                                     tagline      title  video  vote_average  \\\n",
       "0                                        NaN  Toy Story  False           7.7   \n",
       "1  Roll the dice and unleash the excitement!    Jumanji  False           6.9   \n",
       "\n",
       "   vote_count                                               cast  \\\n",
       "0      5415.0  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
       "1      2413.0  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
       "\n",
       "                                                crew  \\\n",
       "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...   \n",
       "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   \n",
       "\n",
       "                                            keywords  \n",
       "0  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...  \n",
       "1  [{'id': 10090, 'name': 'board game'}, {'id': 1...  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
      "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
      "       'popularity', 'poster_path', 'production_companies',\n",
      "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
      "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
      "       'vote_average', 'vote_count', 'cast', 'crew', 'keywords'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(master_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46628, 27)\n"
     ]
    }
   ],
   "source": [
    "links = links[links['tmdbId'].notnull()]['tmdbId'].astype('int')\n",
    "master_dataset = master_dataset[master_dataset['id'].isin(links)]\n",
    "print(master_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Data cleaning and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating cast, crew and keyword columns by parsing them as their loaded data type is string but need to be converted to list\n",
    "master_dataset['cast'] = master_dataset['cast'].apply(literal_eval)\n",
    "master_dataset['crew'] = master_dataset['crew'].apply(literal_eval)\n",
    "master_dataset['keywords'] = master_dataset['keywords'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating cast to maintain proportion between different lengths (keeping top 3 cast members)\n",
    "master_dataset['cast'] = master_dataset['cast'].apply(\n",
    "    lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "master_dataset['cast'] = master_dataset['cast'].apply(\n",
    "    lambda x: x[:3] if len(x) >= 3 else x)\n",
    "\n",
    "# Setting keywords to empty list if does not exists, otherwise taking into account for each word as keyword\n",
    "master_dataset['keywords'] = master_dataset['keywords'].apply(\n",
    "    lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "\n",
    "# Extracting directory names from the crew\n",
    "master_dataset['director'] = master_dataset['crew'].apply(get_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for uniqueness, removing all the spaces in between the names\n",
    "master_dataset['cast'] = master_dataset['cast'].apply(\n",
    "    lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
    "\n",
    "# Maintaining the original director name as main director\n",
    "master_dataset['main_director'] = master_dataset['director']\n",
    "\n",
    "# Maintaining the number of director to maintain proportion (similar to cast column above)\n",
    "master_dataset['director'] = master_dataset['director'].astype(\n",
    "    'str').apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
    "master_dataset['director']      = master_dataset['director'].apply(lambda x: [x, x,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword\n",
      "woman director      3128\n",
      "independent film    1942\n",
      "murder              1314\n",
      "based on novel       841\n",
      "musical              734\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Stacking the keywords and keeping the movies which containers X number of keywords as minimum\n",
    "s = master_dataset.apply(lambda x: pd.Series(\n",
    "    x['keywords']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'keyword'\n",
    "s = s.value_counts()\n",
    "print(s[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will try to map where more than 1 keyword is present for the movie\n",
    "s = s[s > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object for ENGLISH Stemmer - Snowball to trim down keywords to their stem words\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# Trim down keywords to their stem words and then remove the space between keywords which are having more than 1 length for uniqueness\n",
    "master_dataset['keywords'] = master_dataset['keywords'].apply(\n",
    "    lambda x: [stemmer.stem(i) for i in x])\n",
    "master_dataset['keywords'] = master_dataset['keywords'].apply(\n",
    "    lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [jealousi, toy, boy, friendship, friend, rival...\n",
       "1    [boardgam, disappear, basedonchildren'sbook, n...\n",
       "2       [fish, bestfriend, duringcreditssting, oldmen]\n",
       "Name: keywords, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset['keywords'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a soup feature - combination of (keywords, cast, director, genres)\n",
    "master_dataset['soup'] = master_dataset['keywords'] + \\\n",
    "    master_dataset['cast'] + master_dataset['director'] + \\\n",
    "    master_dataset['genres']\n",
    "\n",
    "# Modifying by placing single space between all the soup words\n",
    "master_dataset['soup'] = master_dataset['soup'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    jealousi toy boy friendship friend rivalri boy...\n",
       "1    boardgam disappear basedonchildren'sbook newho...\n",
       "2    fish bestfriend duringcreditssting oldmen walt...\n",
       "Name: soup, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset['soup'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
      "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
      "       'popularity', 'poster_path', 'production_companies',\n",
      "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
      "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
      "       'vote_average', 'vote_count', 'cast', 'crew', 'keywords', 'director',\n",
      "       'main_director', 'soup'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(master_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unwanted columns from the dataset - these features can be used if you wish to add more features to your recommender system.\n",
    "# We are not going to use them, so we are removing them.\n",
    "master_dataset.drop(['adult', 'belongs_to_collection', 'budget', 'homepage', 'original_language', 'production_companies',\n",
    "                    'production_countries', 'revenue', 'runtime', 'spoken_languages', 'status', 'video'], axis=1, inplace=True)\n",
    "master_dataset.drop(['overview', 'tagline', 'vote_average', 'vote_count',\n",
    "                    'cast', 'crew', 'keywords', 'director'], axis=1, inplace=True)\n",
    "master_dataset.drop(['id', 'imdb_id','original_title','poster_path','genres'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking popularity column for being non-float data type and removing them\n",
    "master_dataset['popularity'] = master_dataset.apply(\n",
    "    lambda r: r['popularity'] if type(r['popularity']) == float else np.nan, axis=1)\n",
    "master_dataset.dropna(inplace=True)\n",
    "\n",
    "# Checking director column for being non-string data type and removing them\n",
    "master_dataset['main_director'] = master_dataset.apply(\n",
    "    lambda r: r['main_director'] if len(r['main_director']) > 1 else np.nan, axis=1)\n",
    "master_dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the whole dataset based on popularity. This will help us to take top X number of movies based on popularity.\n",
    "master_dataset.sort_values(by=['popularity'], ascending=False, inplace=True)\n",
    "\n",
    "# Dropping popularity column after sorting based on popularity\n",
    "master_dataset.drop(['popularity'], axis=1, inplace=True)\n",
    "master_dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index because after sorting, the index values have changed.\n",
    "master_dataset.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Demo, we will take top 2500 movies, which is hosted online already.\n",
    "master_dataset = master_dataset[:2500]\n",
    "\n",
    "# For Tiny-Model, we will take top 1000 movies\n",
    "# master_dataset = master_dataset[:1000]\n",
    "\n",
    "# For Extra-Small-Model, we will take top 5000 movies\n",
    "# master_dataset = master_dataset[:5000]\n",
    "\n",
    "# For Small-Model, we will take top 10000 movies\n",
    "# master_dataset = master_dataset[:10000]\n",
    "\n",
    "# For Medium-Model, we will take top 20000 movies\n",
    "# master_dataset = master_dataset[:20000]\n",
    "\n",
    "# For Large-Model, we will take top 30000 movies\n",
    "# master_dataset = master_dataset[:30000]\n",
    "\n",
    "# LEAVE ALL THE LINES COMMENTED IF YOU WISH TO TRAIN FULL MOVIES DATASET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "      <th>main_director</th>\n",
       "      <th>soup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>Minions</td>\n",
       "      <td>Kyle Balda</td>\n",
       "      <td>assist aftercreditssting duringcreditssting ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-10-24</td>\n",
       "      <td>Big Hero 6</td>\n",
       "      <td>Chris Williams</td>\n",
       "      <td>brotherbrotherrelationship hero talent reveng ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-09</td>\n",
       "      <td>Deadpool</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>antihero mercenari marvelcom superhero basedon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>Guardians of the Galaxy Vol. 2</td>\n",
       "      <td>James Gunn</td>\n",
       "      <td>sequel superhero basedoncom misfit space outer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>cultureclash futur spacewar spacecoloni societ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  release_date                           title   main_director  \\\n",
       "0   2015-06-17                         Minions      Kyle Balda   \n",
       "1   2014-10-24                      Big Hero 6  Chris Williams   \n",
       "2   2016-02-09                        Deadpool      Tim Miller   \n",
       "3   2017-04-19  Guardians of the Galaxy Vol. 2      James Gunn   \n",
       "4   2009-12-10                          Avatar   James Cameron   \n",
       "\n",
       "                                                soup  \n",
       "0  assist aftercreditssting duringcreditssting ev...  \n",
       "1  brotherbrotherrelationship hero talent reveng ...  \n",
       "2  antihero mercenari marvelcom superhero basedon...  \n",
       "3  sequel superhero basedoncom misfit space outer...  \n",
       "4  cultureclash futur spacewar spacecoloni societ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our final dataset which we will be using for training our word and cosine similarity matrix\n",
    "master_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 4)\n"
     ]
    }
   ],
   "source": [
    "print(master_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Recommendation Matrix\n",
    "\n",
    ">     Building the matrix which contains similarity scores between movies based on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Training Word based count vectorizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Count Vectorizer object which will be based on word analyzer, with ngram 1-2 and minimum number of occurances of words as 2\n",
    "count = CountVectorizer(analyzer='word', ngram_range=(\n",
    "    1, 2), min_df=2, stop_words='english')\n",
    "\n",
    "# Adjusting the count vectorizer object with respect to our dataset\n",
    "count_matrix = count.fit_transform(master_dataset['soup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 7277)\n"
     ]
    }
   ],
   "source": [
    "print(count_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Cosine Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We build it as an pyarrow dataframe because it is the most efficient\n",
    "table = pa.Table.from_pandas(pd.DataFrame(\n",
    "    cosine_similarity(count_matrix, count_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model & Data Export\n",
    "\n",
    ">     Exporting the trained model & dataset efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We export the model into parquet format. We have 3 awesome reasons (even recommend for you in your new project)\n",
    "\n",
    "1. Uses Less Storage\n",
    "2. Best Compression Ratio\n",
    "3. Fast & Optimized for efficient Read/Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the Master Dataset\n",
    "master_dataset.to_parquet('/content/movie_database.parquet', engine='fastparquet',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the Matrix table\n",
    "pq.write_table(table, '/content/model.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Inference\n",
    "\n",
    ">     Loading the trained model to execute Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dataset = pd.read_parquet('/content/movie_database.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "      <th>main_director</th>\n",
       "      <th>soup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>Minions</td>\n",
       "      <td>Kyle Balda</td>\n",
       "      <td>assist aftercreditssting duringcreditssting ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-10-24</td>\n",
       "      <td>Big Hero 6</td>\n",
       "      <td>Chris Williams</td>\n",
       "      <td>brotherbrotherrelationship hero talent reveng ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-09</td>\n",
       "      <td>Deadpool</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>antihero mercenari marvelcom superhero basedon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  release_date       title   main_director  \\\n",
       "0   2015-06-17     Minions      Kyle Balda   \n",
       "1   2014-10-24  Big Hero 6  Chris Williams   \n",
       "2   2016-02-09    Deadpool      Tim Miller   \n",
       "\n",
       "                                                soup  \n",
       "0  assist aftercreditssting duringcreditssting ev...  \n",
       "1  brotherbrotherrelationship hero talent reveng ...  \n",
       "2  antihero mercenari marvelcom superhero basedon...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.parquet.read_table('/content/model.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dataset = master_dataset.reset_index()\n",
    "titles = master_dataset['title']\n",
    "indices = pd.Series(master_dataset.index, index=master_dataset['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(movie_id_from_db, movie_db):\n",
    "    try:\n",
    "        sim_scores = list(enumerate(movie_db[movie_id_from_db]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:15]  # get top 15 Recommendations\n",
    "\n",
    "        movie_indices = [i[0] for i in sim_scores]\n",
    "        output = master_dataset.iloc[movie_indices]\n",
    "        output.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        response = []\n",
    "        for i in range(len(output)):\n",
    "            response.append({\n",
    "                'movie_title': output['title'].iloc[i],\n",
    "                'movie_release_date': output['release_date'].iloc[i],\n",
    "                'movie_director': output['main_director'].iloc[i],\n",
    "                'google_link': \"https://www.google.com/search?q=\" + '+'.join(output['title'].iloc[i].strip().split())\n",
    "            })\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"error: \", e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Shawshank Redemption'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_name = input('Enter a movie Name: ')\n",
    "movie_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_index = titles.to_list().index(movie_name)\n",
    "recommendations = get_recommendations(movie_index, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Title                              | Director             | Release Date   \n",
      "--------------------------------------------------------------------------------\n",
      "The Green Mile                           | Frank Darabont       | 1999-12-10     \n",
      "Siberian Education                       | Gabriele Salvatores  | 2013-02-27     \n",
      "The Broken Circle Breakdown              | Felix Van Groeningen | 2012-10-09     \n",
      "Winter Sleep                             | Nuri Bilge Ceylan    | 2014-06-13     \n",
      "I as in Icarus                           | Henri Verneuil       | 1979-12-12     \n",
      "Death Warrant                            | Deran Sarafian       | 1990-09-14     \n",
      "Escape from Alcatraz                     | Don Siegel           | 1979-06-22     \n",
      "London Boulevard                         | William Monahan      | 2010-11-10     \n",
      "American Psycho                          | Mary Harron          | 2000-04-13     \n",
      "Rise of the Footsoldier                  | Julian Gilbey        | 2007-09-07     \n",
      "Bad Boy Bubby                            | Rolf de Heer         | 1993-09-01     \n",
      "Kiss the Girls                           | Gary Fleder          | 1997-10-03     \n",
      "The Yards                                | James Gray           | 2000-04-27     \n",
      "Closed Circuit                           | John Crowley         | 2013-08-28     \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Movie Title':<40} | {'Director':<20} | {'Release Date':<15}\")\n",
    "print(f\"-\"*80)\n",
    "for recommendation in recommendations:\n",
    "    print(\n",
    "        f\"{recommendation['movie_title']:<40} | {recommendation['movie_director']:<20} | {recommendation['movie_release_date']:<15}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
